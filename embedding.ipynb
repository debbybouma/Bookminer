{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing XML/HTML using BeautifulSoup\n",
    "\n",
    "This notebook illustrates how to work with XML/HTML data using a package called BeautifulSoup. Both XML and HTMl are markup languages. Some datasets are provided in XML (Extensible Markup Language), and when you use a web scraper to gather data from websites, chances are your data is in HTML (HyperText Markup Language), since that is the standard markup language for web browser documents (i.e. websites). This notebook is a primer on how to get information from XML/HTML into a format that is processable in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The basic structure of XML/HTML\n",
    "\n",
    "An XML/HTML document consists of elements demarcated by tags, which are organized in a tree structure. Elements can be nested into each other, and multiple elements can be the 'children' of one parent element.\n",
    "\n",
    "### Tags\n",
    "A tag begins with < and ends with >. There are three kinds of tags:\n",
    "- start-tag, e.g. \\<section>\n",
    "- end-tag, e.g. \\</section>\n",
    "- empty-element tag, e.g. \\<line-break />\n",
    "\n",
    "Start-tags and end-tags always appear in pairs (see 'Elements').\n",
    "\n",
    "### Content\n",
    "Any text that is not inside a tag. When processing scraped data for text mining, this is usually where the data you are looking for is.\n",
    "\n",
    "### Elements\n",
    "An element is component of a document that either begins with a start-tag and ends with a matching end-tag, or consists only of an empty-element tag. The characters between the start-tag and end-tag, if any, are the element's content, and may contain markup, including other elements, which are called child elements. An example is <greeting>Hello, world!</greeting>. Another is <line-break />.\n",
    "\n",
    "### Attributes\n",
    "Attributes appear within a start-tag or empty-element tag, and consist of a name–value pair. An example is <img src=\"madonna.jpg\" alt=\"Madonna\" />, where the names of the attributes are \"src\" and \"alt\", and their values are \"madonna.jpg\" and \"Madonna\", respectively. Attributes usually do not contain running text, but they may still be useful in the context of text mining as they may provide useful meta-information or even labels.\n",
    "\n",
    "### Entities\n",
    "Entities are variables used to store text. They are prefaced with & and end with ;.\n",
    "\n",
    "### Comments\n",
    "Comments begin with \\<!-- and end with -->. They are not part of the content. You can think of them as similar to placing a comment after # in Python.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small XML snippet we will be working with*.  I've indented it here so that you can see the structure of the document more clearly. It comes from a dataset of book blurbs which is available through Kaggle.\n",
    "\n",
    "At the 'lowest level' in this document, we have two book elements. The book start tag has two attributes; date and xml:lang. Each of the boook elements has 4 children: title, body, copyright and metadata. metadata has 6 children istelf, and one of them, topics, has a varying number of children again.\n",
    "\n",
    "\\* technically, this is not a valid XML document, as an XML document needs a single root element to be considered well-formed. You will see we are using 'html.parser'; to process well-formed XML you could also use 'xml', but that parser doesn't understand how to deal with our data, as we have multiple root elements. We can use the html.parser because the two formats are so similar."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<book date=\"2018-08-18\" xml:lang=\"en\"> \n",
    "    <title>Bluefish</title>\n",
    "    <body>Thirteen-year-old Travis has a secret: he can’t read. But a shrewd teacher and a sassy girl are about to change everything in this witty and deeply moving novel.Travis is missing his old home in the country, and he’s missing his old hound, Rosco. Now there’s just the cramped place he shares with his well-meaning but alcoholic grandpa, a new school, and the dreaded routine of passing when he’s called on to read out loud. But that’s before Travis meets Mr. McQueen, who doesn’t take “pass” for an answer—a rare teacher whose savvy persistence has Travis slowly unlocking a book on the natural world. And it’s before Travis is noticed by Velveeta, a girl whose wry banter and colorful scarves belie some hard secrets of her own. With sympathy, humor, and disarming honesty, Pat Schmatz brings to life a cast of utterly believable characters—and captures the moments of trust and connection that make all the difference.</body>\n",
    "    <copyright>(c) Penguin Random House</copyright>\n",
    "    <metadata>\n",
    "        <topics>\n",
    "            <d0>Teen & Young Adult</d0>\n",
    "            <d1>Teen & Young Adult Fiction</d1>\n",
    "            <d1>Teen & Young Adult Social Issues</d1>\n",
    "        </topics>\n",
    "        <author>Pat Schmatz</author>\n",
    "        <published>Aug 06, 2013 </published>\n",
    "        <page_num> 240 Pages</page_num>\n",
    "        <isbn>9780763663414</isbn>\n",
    "        <url>https://www.penguinrandomhouse.com/books/214830/bluefish-by-pat-schmatz/</url>\n",
    "    </metadata>\n",
    "</book>\n",
    "<book date=\"2018-08-18\" xml:lang=\"en\"> \n",
    "    <title>Ghost Gone Wild</title>\n",
    "    <body>New York Times bestselling author Carolyn Hart’s good-hearted spirit just can’t say no to an earthly rescue in the fourth Bailey Ruth Ghost novel… As far as emissaries from Heaven’s Department of Good Intentions go, Bailey Ruth is far from the top of the go-to list for assignments in the eyes of her boss, Wiggins. So she’s surprised when she’s dropped off on the outskirts of her old hometown, Adelaide, Oklahoma, at the home of young Nick Magruder. When a window cracks and a rifle barrel is thrust inside, only Bailey Ruth’s hasty intervention saves Nick from taking a bullet. But after she materializes to reassure him, she finds she can’t go back to vanishing. What gives? It turns out Bailey’s been tricked by Nick’s late aunt to come to his rescue, which means Wiggins has no idea where she is—and now she may be trapped in Adelaide forever. Unless she can help snare the person who wants Nick dead…</body>\n",
    "    <copyright>(c) Penguin Random House</copyright>\n",
    "    <metadata>\n",
    "        <topics>\n",
    "            <d2>Cozy Mysteries</d2>\n",
    "            <d0>Fiction</d0>\n",
    "            <d1>Mystery & Suspense</d1>\n",
    "        </topics>\n",
    "        <author>Carolyn Hart</author>\n",
    "        <published>Oct 07, 2014 </published>\n",
    "        <page_num> 304 Pages</page_num>\n",
    "        <isbn>9780425260760</isbn>\n",
    "        <url>https://www.penguinrandomhouse.com/books/312119/ghost-gone-wild-by-carolyn-hart/</url>\n",
    "    </metadata>\n",
    "</book>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BeautifulSoup\n",
    "\n",
    "To process XML using Python, we'll be using a package called Beautiful Soup which provides an xml&html parser. There are other packages available, too. Check if you can `from bs4 import BeautifulSoup` and otherwise install `beautifulsoup4` (do NOT install BeautifulSoup; that is an earlier, now outdated version of the same package). \n",
    "\n",
    "BeautifulSoup documentation: https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to import the package\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "data = open('BlurbGenreCollection_EN_train.txt', 'r', encoding=\"utf8\")\n",
    "\n",
    "# parse the data\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "# cose the file\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the file\n",
    "data2 = open('BlurbGenreCollection_EN_dev.txt', 'r', encoding=\"utf8\")\n",
    "\n",
    "# parse the data\n",
    "soup2 = BeautifulSoup(data2, 'html.parser')\n",
    "\n",
    "# cose the file\n",
    "data2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we find all 'book'elements in the data, and put them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "booklist = soup.find_all('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "booklist2 = soup2.find_all('book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we are interested in the book title, the list of topics and the blurb, as well as the date of data collection. Note that this is not the date the book was published - the latter is an element in the metadata, whereas the former is an attribute of the 'book' element. We'll give every book in our dataset an integer as an ID, and put the whole thing in a Python dictionary.\n",
    "\n",
    "We can accesss an element by concatenating the element names in the tree structure intil we arrive at the element we are interested in. \n",
    "\n",
    "If we only want the content of an element, we can use `contents` or `string`. `contents` contains a list - if you know it only ever contains one field, you can unwrap it by indexing the 0th element.\n",
    "\n",
    "If we want all children of an element, regardless of their type, we can use `findChildren()`.\n",
    "\n",
    "If we want to find an attribute, we use `get()` with the name of the attribute as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = {} # this will be the big dictionary that contains all our data\n",
    "book_id = 1\n",
    "\n",
    "for book in booklist:\n",
    "    # Title\n",
    "    title = book.title.contents[0] # contents returns a list; we know there is always only 1 title, so we are interested in the element at position 0\n",
    "    \n",
    "    # Topics\n",
    "    topics = []\n",
    "    topictags = book.metadata.topics.d0.contents[0] # we want to find all main topics (d0)\n",
    "   \n",
    "    # Blurb\n",
    "    blurb = book.body.string\n",
    "    \n",
    "    # Date of data collection. This is the date that is an attribute of the book opening tag (not the date under 'published')\n",
    "    date_collected = book.get('date')\n",
    "\n",
    "    #put everything in a dictionary, and add it to our big data dictionary with the current book ID as key\n",
    "    book_data[book_id] = {'title' : title,\n",
    "                         'topics' : topictags,\n",
    "                         'blurb' : blurb,\n",
    "                         'date_of_data_collection' : date_collected}\n",
    "    \n",
    "    \n",
    "    book_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data2 = {} # this will be the big dictionary that contains all our data\n",
    "book_id = 1\n",
    "\n",
    "for book in booklist2:\n",
    "    # Title\n",
    "    title = book.title.contents[0] # contents returns a list; we know there is always only 1 title, so we are interested in the element at position 0\n",
    "    \n",
    "    # Topics\n",
    "    topics = []\n",
    "    topictags = book.metadata.topics.d0.contents[0] # we want to find all main topics (d0)\n",
    "    \n",
    "    # Blurb\n",
    "    blurb = book.body.string\n",
    "    \n",
    "    # Date of data collection. This is the date that is an attribute of the book opening tag (not the date under 'published')\n",
    "    date_collected = book.get('date')\n",
    "\n",
    "    #put everything in a dictionary, and add it to our big data dictionary with the current book ID as key\n",
    "    book_data2[book_id] = {'title' : title,\n",
    "                         'topics' : topictags,\n",
    "                         'blurb' : blurb,\n",
    "                         'date_of_data_collection' : date_collected}\n",
    "    \n",
    "    \n",
    "    book_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write dictionary to JSON\n",
    "\n",
    "Now let's save our data as JSON for easier future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"book_data2.json\", \"w\") as f:\n",
    "    j2 = json.dump(book_data2, f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"book_data.json\", \"w\") as f:\n",
    "    j = json.dump(book_data, f)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Google News vectors word-embedding model with 300 nodes.\n",
    "import gensim\n",
    "word_embedding_model = gensim.models.KeyedVectors.load_word2vec_format('C:\\\\Users\\\\benth\\\\Documents\\\\AI\\\\jaar_3\\\\text_mining\\\\ba-text-mining-master\\\\lab_sessions\\\\lab4\\\\GoogleNews-vectors-negative300.bin.gz', binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_books = json.load(open('book_data.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_books = json.load(open('book_data2.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all blurbs from the training set in a list.\n",
    "blurbs_train = []\n",
    "for id_, book_info in training_books.items():\n",
    "    blurbs_train.append(book_info['blurb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all blurbs from the validation set in a list.\n",
    "blurbs_valid = []\n",
    "for id_, book_info in valid_books.items():\n",
    "    blurbs_valid.append(book_info['blurb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess the blurbs by splitting them in tokens and removing stopwords.\n",
    "def preprocess(list_of_blurbs):\n",
    "    result = []\n",
    "    \n",
    "    for blurb in list_of_blurbs:\n",
    "        seperated_tokens_blurb = nltk.word_tokenize(blurb) #split blurb in tokens. \n",
    "        blurb_without_stopwords = []\n",
    "        for token in seperated_tokens_blurb:\n",
    "            stopword_set = set(stopwords.words('english')) #set to search faster\n",
    "            if token not in stopword_set:\n",
    "                blurb_without_stopwords.append(token) #delete stopwords from the blurb.\n",
    "        result.append(blurb_without_stopwords)\n",
    "\n",
    "            \n",
    "        \n",
    "    return(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_train_blurbs = preprocess(blurbs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_valid_blurbs = preprocess(blurbs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make embeddings of the blurbs\n",
    "def make_embedding(blurb):\n",
    "    word_vectors = []\n",
    "    for token in blurb: #first make embeddings for all seperate tokens\n",
    "        if token in word_embedding_model:\n",
    "            vector = word_embedding_model[token] \n",
    "        else:\n",
    "            vector = [0]*300 #if the word is not in the model, we use a zero's-vector.\n",
    "        word_vectors.append(vector)\n",
    "    result = np.average(word_vectors,axis=0) #the vector of the document is the average of all word vectors.\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make every blurb in the training set into an embedding\n",
    "embedded_train_blurbs = list(map(make_embedding, processed_train_blurbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make every blurb in the validation set into an embedding\n",
    "embedded_valid_blurbs = list(map(make_embedding, processed_valid_blurbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the genres in a gold list.\n",
    "genres_train = []\n",
    "for id_, book_info in training_books.items():\n",
    "    genres_train.append(book_info['topics'])\n",
    "        \n",
    "genres_valid = []\n",
    "for id_, book_info in valid_books.items():\n",
    "    genres_valid.append(book_info['topics'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_clf = svm.LinearSVC(multi_class=\"crammer_singer\") #Linear Support Vector classifier to predict the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programms\\anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lin_clf.fit(embedded_train_blurbs, genres_train) #First train on the training set.\n",
    "genre_pred_lin = lin_clf.predict(embedded_valid_blurbs) #predict on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  Children’s Books      0.815     0.825     0.820      3125\n",
      "          Classics      0.752     0.521     0.615       628\n",
      "           Fiction      0.794     0.913     0.850      4889\n",
      "             Humor      0.718     0.226     0.343       226\n",
      "        Nonfiction      0.870     0.902     0.886      5218\n",
      "            Poetry      0.553     0.265     0.359        98\n",
      "Teen & Young Adult      0.781     0.042     0.079       601\n",
      "\n",
      "          accuracy                          0.824     14785\n",
      "         macro avg      0.755     0.528     0.565     14785\n",
      "      weighted avg      0.820     0.824     0.804     14785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(genres_valid,genre_pred_lin,digits=3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "log_reg = linear_model.LogisticRegression() #Linear regression to predict the genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\programms\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "log_reg.fit(embedded_train_blurbs,genres_train) #first train on the training set.\n",
    "genre_pred_log = log_reg.predict(embedded_valid_blurbs) #predict on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  Children’s Books      0.822     0.813     0.817      3125\n",
      "          Classics      0.703     0.538     0.610       628\n",
      "           Fiction      0.792     0.909     0.846      4889\n",
      "             Humor      0.723     0.208     0.323       226\n",
      "        Nonfiction      0.865     0.899     0.882      5218\n",
      "            Poetry      0.533     0.082     0.142        98\n",
      "Teen & Young Adult      0.617     0.097     0.167       601\n",
      "\n",
      "          accuracy                          0.820     14785\n",
      "         macro avg      0.722     0.507     0.541     14785\n",
      "      weighted avg      0.810     0.820     0.802     14785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(genres_valid,genre_pred_log,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Blurb:  As kids, we all had passions — something we loved doing, experienced with our friends, dreamed about every spare moment. For Jay Atkinson, who grew up in a small Massachusetts town, it was hockey. When Bobby Orr scored the winning goal in the 1970 Stanley Cup Finals against the St. Louis Blues, Atkinson became a fan for life. In 1975, he played on the first Methuen Rangers varsity hockey team. Once and always a rink rat, Atkinson still plays hockey whenever and wherever he can. Twenty-five years after he played for the Rangers, Atkinson returns to his high school team as a volunteer assistant. Ice Time tells the team’s story as he follows the temperamental star, the fiery but troubled winger, the lovesick goalie, the rookie whose father is battling cancer, and the \"old school\" coach as the Rangers make a desperate charge into the state tournament. In emotionally vivid detail, Ice Time travels into the rinks, schools, and living rooms of small-town America, where friendships are forged, the rewards of loyalty and perseverance are earned, and boys and girls are transformed into young men and women. Along the way, we also meet his five-year-old son, Liam, who is just now learning the game his father loves. Whether describing kids playing a moonlit game on a frozen swamp or the crucible of team tryouts and predawn bus rides that he endured himself, Atkinson carves out the drama of adolescence with precision and affection. He takes us onto the ice and into the heart of a town and a team as he explores the profound connection between fathers and sons, and what it means to go home again.From the Hardcover edition.\n",
      "Genre:  Nonfiction\n",
      "Predicted by Linear SVC as:  Children’s Books\n",
      "Predicted by Logistic Regression as:  Children’s Books\n"
     ]
    }
   ],
   "source": [
    "i= 1264\n",
    "\n",
    "print(\"Example Blurb: \", blurbs_valid[i])\n",
    "print(\"Genre: \", genres_valid[i])\n",
    "print(\"Predicted by Linear SVC as: \", genre_pred_lin[i])\n",
    "print(\"Predicted by Logistic Regression as: \", genre_pred_log[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we process the test set to get the final results.\n",
    "# open the file\n",
    "data = open('BlurbGenreCollection_EN_test.txt', 'r', encoding=\"utf8\")\n",
    "\n",
    "# parse the data\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "# cose the file\n",
    "data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "booklist = soup.find_all('book')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = {} # this will be the big dictionary that contains all our data\n",
    "book_id = 1\n",
    "\n",
    "for book in booklist:\n",
    "    # Title\n",
    "    title = book.title.contents[0] # contents returns a list; we know there is always only 1 title, so we are interested in the element at position 0\n",
    "    \n",
    "    # Topics\n",
    "    topics = []\n",
    "    topictags = book.metadata.topics.d0.contents[0] # we want to find all main topics (d0)\n",
    "   \n",
    "    # Blurb\n",
    "    blurb = book.body.string\n",
    "    \n",
    "    # Date of data collection. This is the date that is an attribute of the book opening tag (not the date under 'published')\n",
    "    date_collected = book.get('date')\n",
    "\n",
    "    #put everything in a dictionary, and add it to our big data dictionary with the current book ID as key\n",
    "    book_data[book_id] = {'title' : title,\n",
    "                         'topics' : topictags,\n",
    "                         'blurb' : blurb,\n",
    "                         'date_of_data_collection' : date_collected}\n",
    "    \n",
    "    \n",
    "    book_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"book_data_test.json\", \"w\") as f:\n",
    "    j2 = json.dump(book_data, f)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_books = json.load(open('book_data_test.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all blurbs from the training set in a list.\n",
    "blurbs_test = []\n",
    "for id_, book_info in test_books.items():\n",
    "    blurbs_test.append(book_info['blurb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_test_blurbs = preprocess(blurbs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_test_blurbs = list(map(make_embedding, processed_test_blurbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather the genres in a gold list.\n",
    "genres_test = []\n",
    "for id_, book_info in test_books.items():\n",
    "    genres_test.append(book_info['topics'])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_test = lin_clf.predict(embedded_test_blurbs) #predict on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg_test = log_reg.predict(embedded_test_blurbs) #predict on validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  Children’s Books      0.826     0.818     0.822      3903\n",
      "          Classics      0.769     0.519     0.620       776\n",
      "           Fiction      0.790     0.921     0.850      6092\n",
      "             Humor      0.750     0.212     0.331       283\n",
      "        Nonfiction      0.871     0.902     0.886      6477\n",
      "            Poetry      0.554     0.263     0.356       118\n",
      "Teen & Young Adult      0.582     0.043     0.080       745\n",
      "\n",
      "          accuracy                          0.825     18394\n",
      "         macro avg      0.734     0.525     0.564     18394\n",
      "      weighted avg      0.815     0.825     0.805     18394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(genres_test,SVM_test,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "  Children’s Books      0.831     0.807     0.819      3903\n",
      "          Classics      0.710     0.540     0.613       776\n",
      "           Fiction      0.786     0.917     0.846      6092\n",
      "             Humor      0.707     0.145     0.240       283\n",
      "        Nonfiction      0.866     0.896     0.880      6477\n",
      "            Poetry      0.450     0.076     0.130       118\n",
      "Teen & Young Adult      0.620     0.107     0.183       745\n",
      "\n",
      "          accuracy                          0.820     18394\n",
      "         macro avg      0.710     0.498     0.530     18394\n",
      "      weighted avg      0.810     0.820     0.802     18394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(genres_test,LogReg_test,digits=3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
